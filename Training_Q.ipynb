{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_rewards.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, rewards)\n",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Agent chọn hành động\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Thực hiện hành động và nhận về trạng thái mới đã mã hóa, phần thưởng và trạng thái kết thúc\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32md:\\code_etc\\Python\\_File_chay_code\\RL\\Sokoban_Project_inpy\\RL_algorithms.py:27\u001b[0m, in \u001b[0;36mQLearningAgent.choose_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Chọn hành động\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Chọn hành động ngẫu nhiên\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[state_index])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Environment import SokobanEnvironment\n",
    "from RL_algorithms import QLearningAgent\n",
    "from maps import MAPS  # Giả sử bạn đã lưu các bản đồ trong file maps.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Đảm bảo rằng dòng khởi tạo môi trường phải ở trước\n",
    "env = SokobanEnvironment(MAPS[\"level_1\"])\n",
    "\n",
    "# Sau đó mới sử dụng env\n",
    "state = env.reset()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Khởi tạo môi trường với level 1\n",
    "    env = SokobanEnvironment(MAPS[\"level_1\"])\n",
    "\n",
    "    # Định nghĩa số lượng hành động (4 hướng: up, down, left, right)\n",
    "    action_size = 4\n",
    "\n",
    "    # Khởi tạo agent với state_size dựa trên không gian trạng thái mã hóa\n",
    "    state_size = env.state_space_size()  # Tính toán số lượng trạng thái có thể\n",
    "    agent = QLearningAgent(state_size=state_size, action_size=action_size)  \n",
    "\n",
    "    episodes = 1000\n",
    "    rewards = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        # Đặt lại môi trường và lấy trạng thái ban đầu đã mã hóa\n",
    "        state = env.reset()\n",
    "        state = env.encode_state()  # Mã hóa trạng thái\n",
    "\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Agent chọn hành động\n",
    "            action = agent.choose_action(state)\n",
    "\n",
    "            # Thực hiện hành động và nhận về trạng thái mới đã mã hóa, phần thưởng và trạng thái kết thúc\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            # Agent học từ hành động và trạng thái mới\n",
    "            agent.learn(state, action, reward, next_state, done)\n",
    "\n",
    "            # Cập nhật trạng thái hiện tại\n",
    "            state = next_state\n",
    "\n",
    "            # Cộng dồn phần thưởng\n",
    "            total_reward += reward\n",
    "\n",
    "        # Ghi nhận tổng phần thưởng trong mỗi episode\n",
    "        rewards.append(total_reward)\n",
    "\n",
    "        # In ra tổng phần thưởng sau mỗi 100 episodes\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            print(f'Episode {episode + 1}/{episodes}, Total Reward: {total_reward:.2f}')\n",
    "\n",
    "    # Vẽ biểu đồ phần thưởng theo từng episode\n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Training Progress')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "np.save(\"total_rewards.npy\", rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
